{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ff7dd1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b76c4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f9fdf",
   "metadata": {},
   "source": [
    "## Preprocessing + calculating word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47cf1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    url_pattern = r'https?:\\/\\/(?:www\\.)?[^\\s\\/$.?#].[^\\s]*'\n",
    "    text = re.sub(url_pattern, 'url', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "def create_word_counts(texts, max_vocab_size=None):\n",
    "    word_counts = []\n",
    "    word_freq = Counter()\n",
    "\n",
    "    # Count word occurrences across all texts\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        word_count = Counter(words)\n",
    "        word_counts.append(word_count)\n",
    "        word_freq.update(word_count)\n",
    "    \n",
    "    # Limit vocabulary to the most frequent words, if required\n",
    "    vocabulary = dict(word_freq.most_common(max_vocab_size)) if max_vocab_size else dict(word_freq)\n",
    "    \n",
    "    return word_counts, set(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed1b30",
   "metadata": {},
   "source": [
    "## Naive Bayes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8361eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(word_counts, labels, vocabulary, alpha=1.0):\n",
    "    num_classes = 2\n",
    "    class_counts = np.bincount(labels)\n",
    "    word_counts_by_class = {0: {word: 0 for word in vocabulary}, 1: {word: 0 for word in vocabulary}}\n",
    "    word_totals = np.zeros(num_classes)  # Array for storing sum of words in each class\n",
    "\n",
    "    # Count word frequencies by class\n",
    "    for i in range(len(word_counts)):\n",
    "        label = labels[i]\n",
    "        for word, count in word_counts[i].items():\n",
    "            if word in vocabulary:\n",
    "                word_counts_by_class[label][word] += count\n",
    "                word_totals[label] += count \n",
    "    \n",
    "    # Calculate prior probabilities\n",
    "    priors = class_counts / len(labels)\n",
    "    \n",
    "    # Calculate conditional probabilities with Laplace smoothing\n",
    "    num_words = len(vocabulary)\n",
    "    conditional_probs = {c: {} for c in range(num_classes)}\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        for word in vocabulary:\n",
    "            word_count = word_counts_by_class[c].get(word, 0)\n",
    "            conditional_probs[c][word] = (word_count + alpha) / (word_totals[c] + alpha * num_words)\n",
    "    \n",
    "    return priors, conditional_probs\n",
    "\n",
    "\n",
    "def predict_naive_bayes(word_counts, priors, conditional_probs, vocabulary):\n",
    "    predictions = []\n",
    "\n",
    "    for count in word_counts:\n",
    "        log_probs = np.log(priors)  \n",
    "        for word, word_count in count.items():\n",
    "            if word in vocabulary:\n",
    "                # Calculate log-probability for each class\n",
    "                for c in range(len(priors)):\n",
    "                    log_probs[c] += word_count * np.log(conditional_probs[c].get(word, 1e-10))  # Small epsilon to avoid log(0)\n",
    "        \n",
    "        # Choose the class with the higher log probability\n",
    "        predictions.append(np.argmax(log_probs))  \n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abacdebf",
   "metadata": {},
   "source": [
    "## Define file paths and function to save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cab59434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, output_file_path):\n",
    "    np.savetxt(output_file_path, predictions, fmt='%d', newline='\\n')\n",
    "    print(f\"Saved output to {output_file_path}\")\n",
    "\n",
    "\n",
    "# File paths\n",
    "input_file_path = './spam-classification/train/in.tsv'\n",
    "expected_file_path = './spam-classification/train/expected.tsv'\n",
    "test_file_path = './spam-classification/test/in.tsv'\n",
    "output_file_path = './out.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c141f",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba26678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>Feb  &amp;lt;#&amp;gt;  is \\I LOVE U\\\" day. Send dis t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>Actually nvm, got hella cash, we still on for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>We tried to contact you re your reply to our o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>It's ok, at least armand's still around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>No da. I am happy that we sit together na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3800 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     Go until jurong point, crazy.. Available only ...\n",
       "1                         Ok lar... Joking wif u oni...\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     U dun say so early hor... U c already then say...\n",
       "4     Nah I don't think he goes to usf, he lives aro...\n",
       "...                                                 ...\n",
       "3795  Feb  &lt;#&gt;  is \\I LOVE U\\\" day. Send dis t...\n",
       "3796  Actually nvm, got hella cash, we still on for ...\n",
       "3797  We tried to contact you re your reply to our o...\n",
       "3798            It's ok, at least armand's still around\n",
       "3799          No da. I am happy that we sit together na\n",
       "\n",
       "[3800 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train data\n",
    "in_data = pd.read_csv(input_file_path, sep='\\t', header=None, names=['text'])\n",
    "in_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63585288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3800 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         0\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "3795      0\n",
       "3796      0\n",
       "3797      1\n",
       "3798      0\n",
       "3799      0\n",
       "\n",
       "[3800 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_data = pd.read_csv(expected_file_path, sep='\\t', header=None, names=['label'])\n",
    "expected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8c25e",
   "metadata": {},
   "source": [
    "## Preprocess data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e14e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "in_data['cleaned_text'] = in_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Create word counts and vocabulary\n",
    "word_counts_train, vocabulary = create_word_counts(in_data['cleaned_text'])\n",
    "\n",
    "# Prepare training data\n",
    "y_train = expected_data['label'].values\n",
    "\n",
    "# Train Naive Bayes model\n",
    "priors, conditional_probs = train_naive_bayes(word_counts_train, y_train, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd26fa",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da619f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yup song bro. No creative. Neva test quality. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No dude, its not fake..my frnds got money, tht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dude while were makin those weirdy brownies my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URGENT! We are trying to contact you. Last wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pls dont restrict her from eating anythin she ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>Will ï¿½_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1770 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     Yup song bro. No creative. Neva test quality. ...\n",
       "1     No dude, its not fake..my frnds got money, tht...\n",
       "2     Dude while were makin those weirdy brownies my...\n",
       "3     URGENT! We are trying to contact you. Last wee...\n",
       "4     Pls dont restrict her from eating anythin she ...\n",
       "...                                                 ...\n",
       "1765  This is the 2nd time we have tried 2 contact u...\n",
       "1766              Will ï¿½_ b going to esplanade fr home?\n",
       "1767  Pity, * was in mood for that. So...any other s...\n",
       "1768  The guy did some bitching but I acted like i'd...\n",
       "1769                         Rofl. Its true to its name\n",
       "\n",
       "[1770 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_file_path, sep='\\t', header=None, names=['text'])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f0f39",
   "metadata": {},
   "source": [
    "## Preprocess test data and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01a9e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to ./out.tsv\n",
      "Number of data in class non-spam is 1552\n",
      "Number of data in class spam is 218\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data\n",
    "test_data['cleaned_text'] = test_data['text'].apply(preprocess_text)\n",
    "word_counts_test, _ = create_word_counts(test_data['cleaned_text'])\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = predict_naive_bayes(word_counts_test, priors, conditional_probs, vocabulary)\n",
    "\n",
    "# Save predictions to file\n",
    "save_predictions(y_pred, output_file_path)\n",
    "\n",
    "# Print class counts\n",
    "class_counts = np.bincount(y_pred)\n",
    "print(f'Number of data in class non-spam is {class_counts[0]}')\n",
    "print(f'Number of data in class spam is {class_counts[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708ef3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NLP-Project)",
   "language": "python",
   "name": "nlp-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
